{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with MLlib\n",
    "\n",
    "In this Notebook, we will review the RDD-Based Machine Learning library MLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "First, we have to understand the different data structures used by MLlib. In particular, they are:\n",
    "\n",
    "    * Vectors\n",
    "    * Labeled Points\n",
    "    * Rating\n",
    "    * Model Classes\n",
    "    \n",
    "We will se `Vectors` and `Labeled Points` in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Vector()` --> to hold the features values. It can be `dense` and `sparse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectorDense = [1.0,1.0,2.0,2.0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.0,1.0,2.0,2.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vectorDense = Vectors.dense(Array(1.0,1.0,2.0,2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectorSparse = (4,[0,2],[1.0,2.0])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,[0,2],[1.0,2.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vectorSparse = Vectors.sparse(4, Array(0, 2), Array(1.0, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LabeledPoint()` --> hold both features values and label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.regression.LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelPoint = (1.0,[1.0,1.0,2.0,2.0])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1.0,[1.0,1.0,2.0,2.0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelPoint = LabeledPoint(1, vectorDense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "In this section, we will review the different algorithms associated with Machine Learning problems. Among other, we could highlight the following families of algorithms:\n",
    "\n",
    "    * Feature Extraction\n",
    "    * Statistics\n",
    "    * Classification and Regression\n",
    "    * Collaborative Filtering and Recommendation\n",
    "    * Dimensionality Reduction\n",
    "    * Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "ML algorithms only accept numerical values as inputs. Here, we discuss some algorithm that help us to translate some inputs (like text, non-scaled numerical vectors, etc) to numerical values that ML algorithms can understand. In particular, we will discuss the following algorithms:\n",
    "\n",
    "    * TD-IDF\n",
    "    * Scaling\n",
    "    * Normalization\n",
    "    * Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### td-idf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`td-idf()` --> Term Frecuency - Inverse Document Frequency, useful to convert text input to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.feature.{HashingTF, IDF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentences = ParallelCollectionRDD[0] at parallelize at <console>:30\n",
       "words = MapPartitionsRDD[1] at map at <console>:31\n",
       "tf = org.apache.spark.mllib.feature.HashingTF@71a5849e\n",
       "tfVectors = MapPartitionsRDD[2] at map at HashingTF.scala:120\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at map at HashingTF.scala:120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sentences = sc.parallelize(Array(\"hello\", \"hello how are you\", \"good bye\", \"bye\"))\n",
    "val words = sentences.map(_.split(\" \").toSeq)\n",
    "val tf = new HashingTF(100)\n",
    "val tfVectors = tf.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100,[48],[1.0]), (100,[25,37,38,48],[1.0,1.0,1.0,1.0]), (100,[5,68],[1.0,1.0]), (100,[5],[1.0])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfVectors.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idf = org.apache.spark.mllib.feature.IDF@21d1b236\n",
       "idfModel = org.apache.spark.mllib.feature.IDFModel@4d8bc766\n",
       "tfIdfVectors = MapPartitionsRDD[7] at mapPartitions at IDF.scala:178\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at mapPartitions at IDF.scala:178"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val idf = new IDF()\n",
    "val idfModel = idf.fit(tfVectors)\n",
    "val tfIdfVectors = idfModel.transform(tfVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100,[48],[0.5108256237659907]), (100,[25,37,38,48],[0.9162907318741551,0.9162907318741551,0.9162907318741551,0.5108256237659907]), (100,[5,68],[0.5108256237659907,0.9162907318741551]), (100,[5],[0.5108256237659907])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdfVectors.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vect\n",
    "\n",
    "`Word2Vec` --> also useful to tranform text into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.feature.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2vec = org.apache.spark.mllib.feature.Word2Vec@576b7754\n",
       "word2vecModel = org.apache.spark.mllib.feature.Word2VecModel@1e0cdbd1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.feature.Word2VecModel@1e0cdbd1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val word2vec = new Word2Vec().setMinCount(0)\n",
    "val word2vecModel = word2vec.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2vecVectors = [0.0024051424115896225,0.0024265004321932793,0.003939271904528141,0.004567727446556091,-0.0017529428005218506,4.160736862104386E-4,0.0031681915279477835,8.893151534721255E-4,-0.002022825414314866,0.004433310125023127,-0.0030568328220397234,0.003593616420403123,0.0017325482331216335,-0.004822498187422752,-0.002658026060089469,-5.373888416215777E-4,-0.004821146838366985,-0.001790562178939581,-0.00481686694547534,-0.004933829419314861,0.0021309254225343466,-0.0010357925202697515,0.0012177051976323128,7.862550555728376E-4,-0.0033831512555480003,0.0017680389573797584,0.00233650510199368,-0.00357298762537539,-0.0011263885535299778,-4.385605570860207E-4,0.0020018289797008038,0.0033215349540114403,0.004542876500636339,0.0016289004124701023...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.0024051424115896225,0.0024265004321932793,0.003939271904528141,0.004567727446556091,-0.0017529428005218506,4.160736862104386E-4,0.0031681915279477835,8.893151534721255E-4,-0.002022825414314866,0.004433310125023127,-0.0030568328220397234,0.003593616420403123,0.0017325482331216335,-0.004822498187422752,-0.002658026060089469,-5.373888416215777E-4,-0.004821146838366985,-0.001790562178939581,-0.00481686694547534,-0.004933829419314861,0.0021309254225343466,-0.0010357925202697515,0.0012177051976323128,7.862550555728376E-4,-0.0033831512555480003,0.0017680389573797584,0.00233650510199368,-0.00357298762537539,-0.0011263885535299778,-4.385605570860207E-4,0.0020018289797008038,0.0033215349540114403,0.004542876500636339,0.0016289004124701023,0.0016515826573595405,0.0022391413804143667,-8.887116564437747E-4,-0.0032134903594851494,0.001556847244501114,-0.0012816108064725995,-0.0024765771813690662,-0.0030194150749593973,-0.002288764575496316,-0.0018253488233312964,0.004293504636734724,-0.004057794343680143,0.004411086905747652,-6.709705339744687E-4,1.797020813683048E-4,-0.002307634800672531,8.289461839012802E-4,0.00460607698187232,0.0011984796728938818,-0.0010753485839813948,-0.004242841619998217,9.039761789608747E-5,9.271029848605394E-4,-0.0022937438916414976,-0.0016159985680133104,0.0038425098173320293,7.381777977570891E-4,0.001908431644551456,0.001852604327723384,6.57918062643148E-5,0.0023659232538193464,6.236082990653813E-4,-0.0011157325934618711,8.241977047873661E-5,-0.002070944756269455,0.004098024684935808,-0.0014683856861665845,7.167673320509493E-4,-0.004369341768324375,-0.003329662373289466,-0.0026891841553151608,0.003414849517866969,-0.003412605496123433,0.0038826637901365757,-0.0011359861819073558,-0.0021462258882820606,-0.0030949003994464874,-0.0013073001755401492,0.004183411132544279,0.0013402109034359455,-0.0027947849594056606,-0.0011525510344654322,3.842780424747616E-4,0.00131686229724437,-0.002193661406636238,0.004862440750002861,-0.0029729206580668688,0.001962461043149233,3.091102698817849E-4,2.605594345368445E-4,0.0019118096679449081,-0.0031120942439883947,-0.004096286371350288,-0.001282493700273335,0.002961480524390936,-0.0034863906912505627]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val word2vecVectors = word2vecModel.transform(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling\n",
    "\n",
    "While our input data could be already numeric, it is useful sometimes for the ML algorithms to scale that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler()` --> to scale numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.feature.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectors = Array([-2.0,5.0,1.0,4.0], [2.0,0.0,1.0,7.2], [4.0,2.0,0.5,0.8])\n",
       "vectorsRdd = ParallelCollectionRDD[20] at parallelize at <console>:36\n",
       "scaler = org.apache.spark.mllib.feature.StandardScaler@4172ba3a\n",
       "model = org.apache.spark.mllib.feature.StandardScalerModel@1ec24b33\n",
       "scaledData = MapPartitionsRDD[25] at map at VectorTransformer.scala:52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[25] at map at VectorTransformer.scala:52"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vectors = Array(Vectors.dense(Array(-2.0, 5.0, 1.0, 4.0)),\n",
    "                    Vectors.dense(Array(2.0, 0.0, 1.0, 7.2)),\n",
    "                    Vectors.dense(Array(4.0, 2.0, 0.5, 0.8)))\n",
    "\n",
    "val vectorsRdd = sc.parallelize(vectors)\n",
    "val scaler = new StandardScaler(withMean=true, withStd=true)\n",
    "val model = scaler.fit(vectorsRdd)\n",
    "val scaledData = model.transform(vectorsRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0910894511799618,1.0596258856520353,0.5773502691896257,0.0], [0.2182178902359923,-0.9271726499455306,0.5773502691896257,1.0], [0.8728715609439694,-0.13245323570650427,-1.1547005383792517,-1.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledData.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "\n",
    "As with scaling, sometimes it is very usefull to normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.feature.Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm = org.apache.spark.mllib.feature.Normalizer@7f735a13\n",
       "normData = MapPartitionsRDD[26] at map at VectorTransformer.scala:52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[26] at map at VectorTransformer.scala:52"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val norm = new Normalizer()\n",
    "val normData = norm.transform(vectorsRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.29488391230979427,0.7372097807744856,0.14744195615489714,0.5897678246195885], [0.2652790545386455,0.0,0.13263952726932274,0.9550045963391238], [0.8751666735874727,0.43758333679373634,0.10939583419843409,0.17503333471749455]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normData.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "The library MLlib includes useful functionalities to calculate some main statistics over numeric RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.stat.Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### colStats()\n",
    "\n",
    "`colStats()` --> to calculate statistics over an RDD of numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colStats = org.apache.spark.mllib.stat.MultivariateOnlineSummarizer@56711efb\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.stat.MultivariateOnlineSummarizer@56711efb"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colStats = Statistics.colStats(vectorsRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colStatsMap = Map(count -> 3, variance -> [9.333333333333334,6.333333333333333,0.08333333333333333,10.240000000000002], mean -> [1.3333333333333333,2.333333333333333,0.8333333333333334,4.0], numNonzeros -> [3.0,2.0,3.0,3.0], min -> [-2.0,0.0,0.5,0.8], normL1 -> [8.0,7.0,2.5,12.0], normL2 -> [4.898979485566356,5.385164807134504,1.5,8.27526434623088], max -> [4.0,5.0,1.0,7.2])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(count -> 3, variance -> [9.333333333333334,6.333333333333333,0.08333333333333333,10.240000000000002], mean -> [1.3333333333333333,2.333333333333333,0.8333333333333334,4.0], numNonzeros -> [3.0,2.0,3.0,3.0], min -> [-2.0,0.0,0.5,0.8], normL1 -> [8.0,7.0,2.5,12.0], normL2 -> [4.898979485566356,5.385164807134504,1.5,8.27526434623088], max -> [4.0,5.0,1.0,7.2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colStatsMap = Map(\"count\" -> colStats.count, \n",
    "                      \"max\" -> colStats.max,\n",
    "                      \"mean\" -> colStats.mean,\n",
    "                      \"min\" -> colStats.min,\n",
    "                      \"normL1\" -> colStats.normL1,\n",
    "                      \"normL2\" -> colStats.normL2,\n",
    "                      \"numNonzeros\" -> colStats.numNonzeros,\n",
    "                      \"variance\" -> colStats.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 3\n",
      "variance: [9.333333333333334,6.333333333333333,0.08333333333333333,10.240000000000002]\n",
      "mean: [1.3333333333333333,2.333333333333333,0.8333333333333334,4.0]\n",
      "numNonzeros: [3.0,2.0,3.0,3.0]\n",
      "min: [-2.0,0.0,0.5,0.8]\n",
      "normL1: [8.0,7.0,2.5,12.0]\n",
      "normL2: [4.898979485566356,5.385164807134504,1.5,8.27526434623088]\n",
      "max: [4.0,5.0,1.0,7.2]\n"
     ]
    }
   ],
   "source": [
    "colStatsMap.foreach{case(key, value) => println(key + \": \" + value)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corr()\n",
    "\n",
    "`corr()` --> to calculate the correlation matrix between the columns of one RDD or between two RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0                  -0.7370434740955019   -0.755928946018455   -0.3273268353539885   \n",
       "-0.7370434740955019  1.0                   0.11470786693528112  -0.39735970711951274  \n",
       "-0.755928946018455   0.11470786693528112   1.0                  0.8660254037844397    \n",
       "-0.3273268353539885  -0.39735970711951274  0.8660254037844397   1.0                   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(vectorsRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data1 = ParallelCollectionRDD[39] at parallelize at <console>:35\n",
       "data2 = ParallelCollectionRDD[40] at parallelize at <console>:36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[40] at parallelize at <console>:36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data1: RDD[Double] = sc.parallelize(Array(1, 2, 3, 4, 5))\n",
    "val data2: RDD[Double] = sc.parallelize(Array(10, 19, 32, 41, 56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996326893005933"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(data1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chiSqTest()\n",
    "\n",
    "`chiSqTest()` --> to compute the Pearson's independence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelPointRdd = MapPartitionsRDD[51] at map at <console>:38\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[51] at map at <console>:38"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelPointRdd = vectorsRdd.map(x => LabeledPoint(0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chiSqTest = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0\n",
       "statistic = 0.0\n",
       "pValue = 1.0\n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0\n",
       "statistic = 0.0\n",
       "pValue = 1.0\n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0\n",
       "statistic = 0.0\n",
       "pValue = 1.0\n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0\n",
       "statistic = 0.0\n",
       "pValue = 1.0\n",
       "No presumption against null hypothesi...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0 \n",
       "statistic = 0.0 \n",
       "pValue = 1.0 \n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0 \n",
       "statistic = 0.0 \n",
       "pValue = 1.0 \n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0 \n",
       "statistic = 0.0 \n",
       "pValue = 1.0 \n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 0 \n",
       "statistic = 0.0 \n",
       "pValue = 1.0 \n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val chiSqTest = Statistics.chiSqTest(labelPointRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test value: 1.0\n",
      "Test value: 1.0\n",
      "Test value: 1.0\n",
      "Test value: 1.0\n"
     ]
    }
   ],
   "source": [
    "chiSqTest.foreach(x => println(\"Test value: \" + x.pValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: Regression\n",
    "\n",
    "In this section, we will explore the conventional Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "randGenerator = java.util.Random@ff982dd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "java.util.Random@ff982dd"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.Random\n",
    "val randGenerator = new Random()\n",
    "import org.apache.spark.mllib.regression.LinearRegressionWithSGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create training data according to a Linear Regression model with the following weights:\n",
    "\n",
    "    * Weights: [2.5, 1.25, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regFeatures = Vector(Vector(4, 3, 11, 17), Vector(18, 17, 0, 12), Vector(7, 0, 18, 11), Vector(19, 19, 1, 16), Vector(4, 8, 19, 0), Vector(13, 12, 13, 10), Vector(12, 4, 6, 12), Vector(19, 1, 2, 2), Vector(9, 8, 19, 7), Vector(4, 3, 5, 6), Vector(10, 4, 17, 2), Vector(14, 16, 17, 11), Vector(17, 16, 2, 17), Vector(3, 16, 18, 1), Vector(16, 12, 18, 11), Vector(0, 15, 5, 1), Vector(3, 16, 11, 1), Vector(1, 5, 12, 5), Vector(10, 8, 3, 14), Vector(18, 17, 7, 16), Vector(1, 9, 15, 9), Vector(17, 12, 0, 9), Vector(5, 6, 8, 8), Vector(15, 4, 0, 12), Vector(10, 7, 13, 7), Vector(18, 18, 13, 9), Vector(12, 0, 2, 14), Vector(1, 2, 13, 18), Vector(12, 11, 0, 11), Vector(1, 2, 9, 17), Vector(10, 5, 16, 17), Vector(4,...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(Vector(4, 3, 11, 17), Vector(18, 17, 0, 12), Vector(7, 0, 18, 11), Vector(19, 19, 1, 16), Vector(4, 8, 19, 0), Vector(13, 12, 13, 10), Vector(12, 4, 6, 12), Vector(19, 1, 2, 2), Vector(9, 8, 19, 7), Vector(4, 3, 5, 6), Vector(10, 4, 17, 2), Vector(14, 16, 17, 11), Vector(17, 16, 2, 17), Vector(3, 16, 18, 1), Vector(16, 12, 18, 11), Vector(0, 15, 5, 1), Vector(3, 16, 11, 1), Vector(1, 5, 12, 5), Vector(10, 8, 3, 14), Vector(18, 17, 7, 16), Vector(1, 9, 15, 9), Vector(17, 12, 0, 9), Vector(5, 6, 8, 8), Vector(15, 4, 0, 12), Vector(10, 7, 13, 7), Vector(18, 18, 13, 9), Vector(12, 0, 2, 14), Vector(1, 2, 13, 18), Vector(12, 11, 0, 11), Vector(1, 2, 9, 17), Vector(10, 5, 16, 17), Vector(4, 15, 16, 19), Vector(17, 13, 11, 17), Vector(10, 6, 19, 5), Vector(8, 12, 0, 8), Vector(6, 19, 12, 6), Vector(9, 1, 7, 18), Vector(3, 1, 5, 7), Vector(18, 2, 18, 17), Vector(4, 8, 9, 9), Vector(10, 13, 0, 19), Vector(2, 17, 7, 2), Vector(14, 8, 11, 19), Vector(14, 17, 11, 16), Vector(18, 0, 3, 4), Vector(2, 2, 18, 15), Vector(19, 9, 10, 7), Vector(6, 12, 10, 19), Vector(12, 4, 0, 5), Vector(17, 0, 0, 19), Vector(6, 15, 18, 19), Vector(15, 3, 16, 3), Vector(10, 16, 12, 0), Vector(6, 16, 2, 14), Vector(19, 14, 9, 1), Vector(11, 13, 4, 4), Vector(18, 18, 7, 19), Vector(11, 10, 16, 9), Vector(16, 18, 9, 12), Vector(17, 10, 12, 15), Vector(12, 9, 7, 1), Vector(12, 3, 9, 8), Vector(11, 5, 2, 2), Vector(10, 1, 11, 1), Vector(6, 2, 10, 10), Vector(17, 3, 13, 7), Vector(8, 5, 5, 1), Vector(3, 4, 14, 1), Vector(9, 2, 14, 17), Vector(7, 3, 13, 8), Vector(12, 9, 5, 14), Vector(0, 8, 18, 1), Vector(6, 10, 15, 12), Vector(19, 12, 7, 6), Vector(13, 8, 4, 16), Vector(17, 19, 4, 5), Vector(9, 17, 15, 7), Vector(3, 17, 8, 2), Vector(12, 19, 14, 17), Vector(12, 12, 2, 13), Vector(7, 0, 8, 18), Vector(7, 11, 8, 17), Vector(17, 10, 16, 0), Vector(4, 11, 19, 18), Vector(13, 8, 17, 19), Vector(5, 8, 2, 15), Vector(8, 15, 9, 7), Vector(14, 11, 19, 12), Vector(9, 9, 16, 13), Vector(19, 11, 14, 1), Vector(18, 13, 3, 13), Vector(15, 14, 10, 16), Vector(7, 8, 4, 4), Vector(8, 0, 8, 3), Vector(11, 0, 6, 12), Vector(19, 0, 12, 15), Vector(16, 4, 11, 11), Vector(7, 5, 1, 17), Vector(10, 3, 7, 11), Vector(18, 6, 19, 5), Vector(12, 16, 0, 8), Vector(1, 14, 18, 5), Vector(19, 12, 14, 0), Vector(10, 16, 10, 17), Vector(16, 11, 1, 17), Vector(14, 3, 10, 2), Vector(19, 13, 15, 2), Vector(2, 14, 19, 2), Vector(19, 6, 17, 18), Vector(19, 0, 8, 14), Vector(7, 1, 15, 19), Vector(16, 1, 8, 3), Vector(5, 16, 14, 0), Vector(16, 8, 5, 8), Vector(10, 18, 4, 10), Vector(10, 14, 17, 9), Vector(10, 12, 15, 14), Vector(3, 12, 5, 5), Vector(7, 4, 3, 5), Vector(16, 18, 16, 17), Vector(14, 12, 11, 6), Vector(6, 16, 18, 14), Vector(15, 8, 8, 3), Vector(7, 7, 10, 14), Vector(0, 11, 15, 8), Vector(8, 6, 6, 15), Vector(10, 17, 1, 14), Vector(14, 4, 16, 6), Vector(13, 7, 14, 13), Vector(3, 15, 0, 16), Vector(10, 13, 1, 17), Vector(16, 0, 6, 12), Vector(12, 10, 0, 12), Vector(14, 8, 18, 15), Vector(6, 7, 9, 2), Vector(7, 16, 16, 14), Vector(9, 1, 17, 19), Vector(3, 2, 16, 11), Vector(3, 6, 13, 17), Vector(2, 1, 0, 0), Vector(12, 11, 18, 10), Vector(6, 4, 3, 18), Vector(5, 4, 4, 13), Vector(6, 3, 9, 14), Vector(17, 13, 3, 10), Vector(7, 12, 17, 19), Vector(18, 18, 2, 17), Vector(8, 3, 5, 18), Vector(10, 8, 17, 2), Vector(19, 6, 6, 3), Vector(8, 2, 12, 3), Vector(12, 4, 11, 18), Vector(10, 4, 16, 0), Vector(11, 1, 4, 15), Vector(18, 15, 19, 2), Vector(2, 5, 9, 0), Vector(12, 2, 5, 12), Vector(1, 4, 10, 3), Vector(19, 10, 7, 17), Vector(8, 8, 14, 17), Vector(5, 2, 13, 7), Vector(18, 2, 17, 4), Vector(9, 3, 5, 0), Vector(5, 15, 15, 5), Vector(12, 1, 18, 4), Vector(17, 4, 1, 13), Vector(6, 12, 19, 1), Vector(6, 1, 9, 0), Vector(8, 15, 8, 9), Vector(16, 2, 0, 13), Vector(5, 19, 18, 7), Vector(12, 17, 5, 11), Vector(7, 9, 9, 18), Vector(11, 5, 4, 14), Vector(9, 7, 14, 0), Vector(11, 13, 17, 14), Vector(4, 15, 11, 4), Vector(17, 9, 8, 2), Vector(0, 11, 15, 0), Vector(19, 0, 0, 2), Vector(17, 17, 12, 7), Vector(18, 3, 6, 18), Vector(16, 4, 19, 18), Vector(6, 0, 5, 4), Vector(9, 1, 8, 7), Vector(18, 19, 18, 1), Vector(4, 7, 1, 13), Vector(19, 6, 7, 11), Vector(2, 15, 5, 5), Vector(14, 19, 12, 12), Vector(19, 11, 19, 8), Vector(0, 4, 10, 9), Vector(15, 18, 17, 1), Vector(15, 13, 9, 3), Vector(10, 14, 15, 19), Vector(4, 18, 7, 2), Vector(10, 9, 15, 17), Vector(7, 16, 14, 0), Vector(9, 12, 16, 4), Vector(12, 3, 8, 18), Vector(5, 14, 13, 8), Vector(10, 14, 18, 19), Vector(19, 5, 1, 7), Vector(8, 1, 15, 10), Vector(16, 19, 14, 3), Vector(6, 14, 12, 19), Vector(4, 3, 0, 0), Vector(7, 16, 7, 6), Vector(5, 17, 13, 19), Vector(14, 11, 13, 3), Vector(17, 16, 19, 7), Vector(10, 13, 13, 7), Vector(6, 15, 19, 12), Vector(15, 1, 9, 1), Vector(19, 3, 5, 14), Vector(4, 0, 10, 10), Vector(14, 18, 11, 10), Vector(16, 10, 13, 3), Vector(16, 3, 17, 13), Vector(19, 1, 14, 18), Vector(14, 11, 4, 18), Vector(5, 2, 2, 1), Vector(5, 17, 5, 16), Vector(11, 9, 10, 17), Vector(3, 6, 16, 1), Vector(14, 5, 4, 12), Vector(18, 18, 16, 15), Vector(1, 13, 14, 19), Vector(18, 16, 19, 18), Vector(0, 8, 18, 16), Vector(19, 5, 19, 12), Vector(9, 5, 14, 4), Vector(14, 5, 13, 4), Vector(8, 3, 11, 13), Vector(10, 12, 18, 15), Vector(8, 18, 12, 13), Vector(0, 2, 10, 13), Vector(4, 15, 6, 13), Vector(5, 7, 11, 12), Vector(1, 7, 19, 11), Vector(17, 11, 17, 10), Vector(16, 5, 9, 11), Vector(4, 14, 13, 7), Vector(18, 7, 17, 5), Vector(18, 1, 19, 17), Vector(10, 4, 6, 1), Vector(4, 10, 6, 6), Vector(11, 16, 9, 5), Vector(1, 8, 4, 5), Vector(1, 13, 0, 2), Vector(15, 0, 16, 17), Vector(2, 12, 5, 10), Vector(14, 0, 9, 8), Vector(2, 18, 13, 7), Vector(18, 4, 2, 0), Vector(8, 19, 15, 6), Vector(10, 7, 6, 8), Vector(8, 9, 0, 5), Vector(9, 18, 15, 11), Vector(17, 1, 11, 13), Vector(1, 13, 13, 12), Vector(7, 17, 4, 12), Vector(15, 19, 9, 0), Vector(7, 0, 18, 19), Vector(12, 9, 7, 11), Vector(3, 8, 19, 8), Vector(4, 3, 6, 3), Vector(17, 7, 8, 5), Vector(3, 6, 13, 11), Vector(13, 17, 19, 19), Vector(13, 4, 2, 0), Vector(9, 19, 18, 4), Vector(11, 10, 0, 18), Vector(10, 3, 7, 8), Vector(13, 16, 6, 8), Vector(10, 9, 15, 11), Vector(0, 19, 6, 15), Vector(5, 19, 5, 5), Vector(19, 10, 17, 7), Vector(13, 1, 18, 4), Vector(11, 14, 7, 6), Vector(12, 5, 0, 5), Vector(5, 14, 1, 9), Vector(6, 19, 2, 2), Vector(3, 18, 13, 2), Vector(10, 6, 11, 13), Vector(5, 3, 2, 0), Vector(16, 5, 0, 11), Vector(4, 0, 2, 17), Vector(5, 2, 4, 6), Vector(14, 14, 17, 8), Vector(0, 14, 7, 11), Vector(18, 9, 5, 18), Vector(0, 14, 17, 8), Vector(14, 17, 17, 9), Vector(13, 7, 13, 7), Vector(17, 14, 4, 0), Vector(6, 18, 17, 16), Vector(13, 3, 1, 12), Vector(5, 13, 14, 14), Vector(12, 10, 2, 1), Vector(4, 8, 14, 13), Vector(0, 9, 14, 13), Vector(16, 7, 4, 5), Vector(0, 2, 1, 3), Vector(6, 14, 3, 14), Vector(2, 15, 17, 13), Vector(7, 12, 16, 6), Vector(4, 15, 4, 14), Vector(17, 18, 3, 5), Vector(17, 11, 2, 8), Vector(14, 6, 3, 16), Vector(7, 5, 17, 2), Vector(13, 5, 8, 1), Vector(4, 3, 13, 15), Vector(18, 7, 1, 11), Vector(16, 4, 0, 0), Vector(0, 18, 4, 12), Vector(14, 6, 8, 10), Vector(14, 7, 6, 1), Vector(0, 18, 17, 9), Vector(0, 19, 10, 0), Vector(5, 11, 9, 13), Vector(9, 11, 5, 6), Vector(6, 7, 12, 13), Vector(4, 0, 8, 1), Vector(11, 11, 0, 14), Vector(4, 2, 7, 7), Vector(1, 7, 19, 5), Vector(18, 5, 9, 16), Vector(16, 7, 18, 5), Vector(16, 11, 11, 15), Vector(7, 14, 6, 0), Vector(5, 6, 16, 9), Vector(5, 15, 6, 2), Vector(1, 0, 4, 3), Vector(3, 18, 5, 4), Vector(12, 18, 2, 4), Vector(12, 3, 18, 6), Vector(12, 7, 15, 17), Vector(11, 14, 16, 9), Vector(4, 14, 7, 19), Vector(5, 7, 10, 5), Vector(9, 0, 5, 4), Vector(14, 4, 2, 19), Vector(9, 18, 5, 13), Vector(19, 10, 15, 8), Vector(0, 7, 11, 5), Vector(2, 19, 8, 12), Vector(1, 4, 3, 11), Vector(6, 2, 4, 19), Vector(3, 6, 3, 12), Vector(14, 16, 6, 3), Vector(6, 17, 14, 2), Vector(7, 13, 16, 7), Vector(4, 8, 17, 2), Vector(8, 17, 17, 16), Vector(6, 18, 2, 6), Vector(3, 11, 9, 16), Vector(19, 19, 2, 15), Vector(11, 8, 13, 14), Vector(10, 4, 12, 8), Vector(9, 8, 13, 11), Vector(9, 17, 2, 16), Vector(1, 11, 0, 15), Vector(2, 10, 4, 16), Vector(12, 1, 7, 12), Vector(5, 1, 18, 2), Vector(5, 2, 8, 17), Vector(9, 18, 8, 11), Vector(13, 10, 2, 8), Vector(10, 11, 9, 17), Vector(1, 2, 11, 16), Vector(18, 15, 6, 12), Vector(16, 13, 0, 3), Vector(6, 2, 10, 0), Vector(16, 11, 1, 13), Vector(12, 19, 6, 6), Vector(8, 5, 0, 14), Vector(16, 12, 19, 18), Vector(16, 2, 8, 3), Vector(12, 5, 8, 3), Vector(1, 11, 7, 1), Vector(6, 10, 7, 14), Vector(7, 11, 2, 8), Vector(18, 19, 5, 17), Vector(19, 3, 5, 5), Vector(18, 18, 12, 10), Vector(13, 11, 9, 16), Vector(7, 9, 6, 8), Vector(9, 2, 8, 19), Vector(12, 3, 1, 8), Vector(0, 10, 13, 12), Vector(19, 15, 6, 17), Vector(17, 9, 15, 9), Vector(5, 17, 7, 14), Vector(14, 8, 4, 11), Vector(0, 18, 15, 8), Vector(18, 19, 16, 11), Vector(4, 7, 11, 1), Vector(13, 7, 12, 15), Vector(12, 18, 16, 10), Vector(5, 19, 13, 3), Vector(0, 15, 18, 13), Vector(1, 11, 16, 4), Vector(2, 8, 4, 14), Vector(18, 7, 1, 2), Vector(18, 17, 18, 10), Vector(11, 11, 15, 7), Vector(9, 8, 12, 3), Vector(3, 8, 3, 1), Vector(19, 2, 6, 13), Vector(11, 18, 18, 15), Vector(6, 15, 12, 15), Vector(18, 12, 13, 12), Vector(19, 10, 13, 10), Vector(7, 6, 16, 14), Vector(4, 14, 2, 4), Vector(18, 1, 5, 12), Vector(11, 5, 6, 10), Vector(0, 14, 8, 1), Vector(7, 16, 8, 15), Vector(14, 10, 2, 9), Vector(19, 16, 6, 1), Vector(11, 4, 16, 18), Vector(11, 19, 18, 11), Vector(0, 6, 3, 12), Vector(15, 12, 12, 9), Vector(9, 2, 15, 12), Vector(9, 10, 0, 13), Vector(10, 3, 6, 18), Vector(1, 5, 10, 9), Vector(8, 5, 8, 2), Vector(6, 3, 11, 17), Vector(15, 3, 6, 6), Vector(3, 16, 12, 9), Vector(0, 8, 4, 17), Vector(17, 6, 8, 13), Vector(18, 17, 8, 9), Vector(1, 16, 12, 19), Vector(14, 16, 7, 17), Vector(0, 10, 10, 17), Vector(9, 12, 4, 12), Vector(16, 4, 4, 11), Vector(17, 2, 2, 8), Vector(6, 6, 3, 12), Vector(2, 9, 9, 3), Vector(16, 6, 14, 14), Vector(13, 6, 0, 17), Vector(9, 1, 2, 8), Vector(0, 4, 7, 19), Vector(2, 8, 14, 11), Vector(14, 17, 17, 13), Vector(17, 0, 14, 6), Vector(1, 19, 19, 13), Vector(9, 6, 5, 15), Vector(13, 3, 18, 5), Vector(18, 11, 4, 13), Vector(5, 9, 10, 12), Vector(3, 12, 18, 16), Vector(18, 5, 1, 5), Vector(5, 3, 0, 18), Vector(5, 18, 16, 17), Vector(8, 12, 8, 1), Vector(5, 19, 14, 13), Vector(18, 1, 12, 1), Vector(12, 17, 13, 9), Vector(6, 5, 2, 2), Vector(17, 13, 18, 10), Vector(18, 0, 2, 8), Vector(8, 0, 14, 8), Vector(14, 4, 0, 14), Vector(7, 9, 13, 13), Vector(6, 9, 1, 11), Vector(9, 8, 13, 0), Vector(12, 18, 3, 19), Vector(10, 19, 1, 13), Vector(9, 17, 0, 17), Vector(4, 15, 15, 11), Vector(6, 11, 1, 6), Vector(9, 10, 4, 4), Vector(5, 9, 4, 9), Vector(16, 0, 0, 3), Vector(3, 15, 16, 8), Vector(3, 9, 12, 19), Vector(17, 8, 1, 17), Vector(19, 12, 10, 4), Vector(1, 4, 19, 14), Vector(1, 14, 9, 0), Vector(7, 8, 13, 15), Vector(16, 15, 16, 12), Vector(11, 17, 19, 15), Vector(14, 8, 1, 14), Vector(15, 9, 14, 15), Vector(10, 3, 19, 17), Vector(2, 7, 17, 13), Vector(17, 1, 14, 16), Vector(9, 11, 7, 18), Vector(3, 6, 11, 5), Vector(14, 11, 17, 4))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val regFeatures = for(_ <- 1 to 500) yield {for (_ <- 1 to 4) yield randGenerator.nextInt(20)}\n",
    "val regFeaturesRdd = sc.parallelize(regFeatures).map(x => Vectors.dense(x.toArray.map(_.toDouble)))\n",
    "val scaler = new StandardScaler()\n",
    "val regFeaturesScale = scaler.fit(regFeaturesRdd).transform(regFeaturesRdd)\n",
    "val regData = regFeaturesScale.map(x => LabeledPoint({\n",
    "    val arrayValue = x.toArray\n",
    "    val randGenerator = new Random()\n",
    "    2.5*x(0) + 1.25*x(1) + 0.5*x(2) + x(3) + randGenerator.nextDouble\n",
    "},x))\n",
    "regData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been created, we can train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numIterations = 10000\n",
       "stepSize = 0.1\n",
       "miniBatchFraction = 1.0\n",
       "lrModel = org.apache.spark.mllib.regression.LinearRegressionModel: intercept = 0.0, numFeatures = 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.regression.LinearRegressionModel: intercept = 0.0, numFeatures = 4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numIterations = 10000\n",
    "val stepSize = 0.1\n",
    "val miniBatchFraction = 1.0\n",
    "val lrModel = LinearRegressionWithSGD.train(regData, numIterations = numIterations, \n",
    "                                            stepSize = stepSize, miniBatchFraction = miniBatchFraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the value of the original and computated weights and intercpet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed weights: [2.378815686036176,1.286597790305558,0.709914794818028,1.1564210592452264]\n",
      "Original weights: [2.5, 1.25, 0.5, 1]\n"
     ]
    }
   ],
   "source": [
    "println(\"Computed weights: \" + lrModel.weights)\n",
    "println(\"Original weights: [2.5, 1.25, 0.5, 1]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
