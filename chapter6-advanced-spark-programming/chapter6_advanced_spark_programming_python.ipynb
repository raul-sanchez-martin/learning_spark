{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Advanced Spark Programming (Python)\n",
    "\n",
    "In this Notebook, we will review the following advanced concepts of Spark:\n",
    "\n",
    "    * Accumulators\n",
    "    * Broadcast Variables\n",
    "    * Partition-Based Functions\n",
    "    * Numeric RDD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Advanced-Spark-Programming\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulators\n",
    "\n",
    "Accumulators are useful for counters shared between different partitions. In the following example, we will count the total number of occurences of the number `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5 = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rdd = sc.parallelize([1,2,5,5,3,6,9,6,5,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [5, 5], [3, 6], [9, 6, 5, 9]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_5(num):\n",
    "    \"\"\"\n",
    "    Increments the accumulator for number 5\n",
    "    \"\"\"\n",
    "    global acc_5\n",
    "    if num == 5:\n",
    "        acc_5 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.map(count_5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator<id=0, value=3>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast Variables\n",
    "\n",
    "Broadcast variables are useful when we want to use the same object in all partitions, and this object is small. This is very commont for example for dictionaries. If the dictionary is going to be used in all the executors to map the values of some keys, using a broadcast variable is very convinient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a numeric key-value RDD, where each value is the squared of the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_key = sc.parallelize([1,2,3,4,5])\n",
    "rdd_key_value = rdd_key.map(lambda x: (x, x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can search now for the value of the key 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_key_value.lookup(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create a big numeric RDD, whose values range from 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_big_keys = sc.parallelize([randint(1,5) for _ in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will find the corresponding values of this key-values using the previous dictionary, converting it to a `Map` (using the function `collectAsMap()`) and the broadcasting this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map = rdd_key_value.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_broad = sc.broadcast(dict_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_big_values = rdd_big_keys.map(lambda key: (key, dict_broad.value.get(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 16),\n",
       " (4, 16),\n",
       " (2, 4),\n",
       " (1, 1),\n",
       " (5, 25),\n",
       " (4, 16),\n",
       " (5, 25),\n",
       " (5, 25),\n",
       " (4, 16),\n",
       " (1, 1),\n",
       " (3, 9),\n",
       " (2, 4),\n",
       " (3, 9),\n",
       " (4, 16),\n",
       " (1, 1),\n",
       " (3, 9),\n",
       " (1, 1),\n",
       " (3, 9),\n",
       " (4, 16),\n",
       " (1, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_big_values.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition-Based Functions\n",
    "\n",
    "Here we will see some special functions that works directly on the partitions of an RDD\n",
    "\n",
    "    * mapPartitions()\n",
    "    * mapPartitionsWithIndex()\n",
    "    * foreachPartition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mapPartitions()`: Iterates over the partitions of an RDD, applying some function. Signature: Input --> Iterator, Output --> Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our numeric rdd with several partitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [5, 5], [3, 6], [9, 6, 5, 9]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 5: 3, 3: 1, 6: 2, 9: 2})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the average of the number of each partition. For that, we create a function called `average_partition()` and use the function `mapPartitions()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_partition(nums):\n",
    "    \"\"\"\n",
    "    Calculates the average of a list of numbers\n",
    "    \n",
    "    :input nums: initial list of numbers\n",
    "    :return: [average (float)]\n",
    "    \"\"\"\n",
    "    \n",
    "    sum_count = [0, 0]\n",
    "    for num in nums:\n",
    "        sum_count[0] += num\n",
    "        sum_count[1] += 1\n",
    "        \n",
    "    return iter([sum_count[0] / sum_count[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.5], [5.0], [4.5], [7.25]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.mapPartitions(average_partition).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [5, 5], [3, 6], [9, 6, 5, 9]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to to the same, but for each output number, we want to indicate its original partition. To do that, we create another function called `average_partition_index()` and use the function `mapPartitionsWithIndex()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_partition_index(index, nums):\n",
    "    \"\"\"\n",
    "    Calculates the average of a list of numbers indicating the \n",
    "    index of the originnal partition\n",
    "    \n",
    "    :input index : index of the current partition\n",
    "    :input nums: initial list of numbers\n",
    "    :return: tuple that contains the index of the original partition\n",
    "    ant the average of its numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    sum_count = [0, 0]\n",
    "    for num in nums:\n",
    "        sum_count[0] += num\n",
    "        sum_count[1] += 1\n",
    "        \n",
    "    return iter((index, sum_count[0] / sum_count[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1.5], [1, 5.0], [2, 4.5], [3, 7.25]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.mapPartitionsWithIndex(average_partition_index).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting function is `foreachPartition()`. It is useful to perform unitary operations for each partition, like for example stablish a conection to an external database. Let's do an easy example using the `num_rdd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"../data/python_logger.txt\"):\n",
    "    os.remove(\"../data/python_logger.txt\")\n",
    "\n",
    "def connect_data_base(partition):\n",
    "    \"\"\"\n",
    "    Function that fakes the connection to a database. For each \n",
    "    new connection, the prase \"Connecting to Database\" is written\n",
    "    in the file \"../data/python_logger.txt\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(\"../data/python_logger.txt\", \"a\") as text_file:\n",
    "        text_file.write(\"Connecting to Database\\n\")\n",
    "        \n",
    "num_rdd.foreachPartition(connect_data_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now, the phrase \"Connecting to Database\" has been written 4 times, one for each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Database\r\n",
      "Connecting to Database\r\n",
      "Connecting to Database\r\n",
      "Connecting to Database\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"../data/python_logger.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric RDD Operations\n",
    "\n",
    "Finally, we are going to explore some built-in numerical operations already included in the RDD API. In particular, we are going to explore the following methods:\n",
    "\n",
    "    * count()\n",
    "    * mean()\n",
    "    * sum()\n",
    "    * max()\n",
    "    * min()\n",
    "    * variance()\n",
    "    * sampleVariance()\n",
    "    * stdev()\n",
    "    * sampleStdev()\n",
    "    * stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count()`: count the number of elements in an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mean()`: mean of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sum()`: cumulative sum of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max()`: maximum value of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min()`: minimum value of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`variance()`: variance of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.290000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sampleVariance()`: variance of the elements of an RDD (using a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.98888888888889"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.sampleVariance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stdev()`: standard deviation of the elements of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5079872407968908"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sampleStdev()`: standard deviation of the elements of an RDD (using a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6436506745197805"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.sampleStdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stats()`: main statistics (count, mean, stdev, max and min) of a numeric RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 10, mean: 5.1, stdev: 2.5079872408, max: 9.0, min: 1.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
